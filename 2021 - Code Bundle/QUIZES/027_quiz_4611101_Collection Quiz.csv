Question,Question Type (multiple-choice or multi-select),Answer Option 1,Answer Option 2,Answer Option 3,Answer Option 4,Answer Option 5,Correct Responses,Explanation
You are accumulating data from IoT devices and you must send data within 10 seconds to Amazon ElasticSearch service. That data should also be consumed by other services when needed. Which service do you recommend using?,multiple-choice,Kinesis Data Streams,Kinesis Data Firehose,SQS,Database Migration Service,,1,
You need a managed service that can deliver data to Amazon S3 and scale automatically for you. You want to be billed only for the actual usage of the service and be able to handle peak loads. Which service do you recommend?,multiple-choice,Kinesis Data Streams,Kinesis Data Firehose,SQS,Kinesis Analytics,,2,
"You are sending a lot of 100B data records and would like to ensure you can use Kinesis to receive your data. What should you use to ensure optimal throughput, that has asynchronous features ?",multiple-choice,Kinesis SDK,Kinesis Producer Library,Kinesis Client Library,Kinesis Connector Library ,Kinesis Agent,2,"Through batching (collection and aggregation), we can achieve maximum throughput using the KPL. KPL is also supporting an asynchronous API"
You would like to collect log files in mass from your Linux servers running on premise. You need a retry mechanism embedded and monitoring through CloudWatch. Logs should end up in Kinesis. What will help you accomplish this?,multiple-choice,Kinesis SDK,Kinesis Producer Library,Kinesis Agent,Direct Connect,,3,
"You would like to perform batch compression before sending data to Kinesis, in order to maximize the throughput. What should you use?",multiple-choice,Kinesis SDK,Kinesis Producer Library Compression Feature,Kinesis Producer Library + Implement Compression Yourself,,,3,Compression must be implemented by the end user
"You have 10 consumers applications consuming concurrently from one shard, in classic mode by issuing GetRecords() commands. What is the average latency for consuming these records for each application?",multiple-choice,70 ms,200 ms,1 sec,2 sec,,4,"You can issue up to 5 GetRecords API calls per second, so it'll take 2 seconds for each consuming application before they can issue their next call"
"You have 10 consumers applications consuming concurrently from one shard, in enhanced fan out mode. What is the average latency for consuming these records for each application?",multiple-choice,70 ms,200 ms,1 sec,2 sec,,1,"here, no matter how many consumers you have, in enhanced fan out mode, each consumer will receive 2MB per second of throughput and have an average latency of 70ms. "
"You would like to have data delivered in near real time to Amazon ElasticSearch, and the data delivery to be managed by AWS. What should you use?",multiple-choice,Kinesis Client Library (KCL),Kinesis Connector Library,Kinesis Firehose,,,3,
"You are consuming from a Kinesis stream with 10 shards that receives on average 8 MB/s of data from various producers using the KPL. You are therefore using the KCL to consume these records, and observe through the CloudWatch metrics that the throughput is 2 MB/s, and therefore your application is lagging. What's the most likely root cause for this issue?",multiple-choice,You need to split shards some more,There's a hot partition,"Cloudwatch is displaying the average throughput metric, not the aggregate one",Your DynamoDB table is under-provisioned ,,4,"Because it's under provisioned, checkpointing does not happen fast enough and results in a lower throughput for your KCL based application. Make sure to increase the RCU / WCU"
You would like to increase the capacity of your Kinesis streams. What should you do?,multiple-choice,Split Shards,Merge Shards,Turn on Auto Scaling,,,1,
Which of the following statement is wrong?,multiple-choice,Spark Streaming can write to Kinesis Data Streams,Spark Streaming can read from Kinesis Data Firehose,Spark Streaming can read from Kinesis Data Streams,,,2,
Which of the following Kinesis Data Firehose does not write to?,multiple-choice,S3,Redshift,DynamoDB,ElasticSearch,Splunk,3,
You are looking to decouple jobs and ensure data is deleted after being processes. Which technology would you choose?,multiple-choice,Kinesis Data Streams,Kinesis Data Firehose,SQS,,,3,
You are collecting data from IoT devices at scale and would like to forward that data into Kinesis Data Firehose. How should you proceed?,multiple-choice,Send that data into an IoT topic and define a rule action,Use enhanced fanout for the IoT topic and send that data into Kinesis Data Streams,"Create an SNS topic, send the IoT data there and use AWS Lambda",Send that data into an IoT topic and use device shadow,,1,
Which protocol is not supported by the IoT Device Gateway?,multiple-choice,MQTT,Websockets,HTTP 1.1,FTP,,4,
You would like to control the target temperature of your room using an IoT thing thermostat. How can you change its state for target temperature even in the case it's temporarily offline?,multiple-choice,Send a message to the IoT broker every 10 seconds until it is acknowledged by the IoT thing,Use a rules actions that triggers when the device comes back online,Change the state of the device shadow,Change its metadata in the thing registry,,3,"That's precisely the purposes of the device shadow, which gets synchronized with the device when it comes back online"
You are looking to continuously replicate a MySQL database that's on premise to Aurora. Which service will allow you to do so securely?,multiple-choice,AWS Direct Connect,Database Migration Services,AWS Lambda,Kinesis Data Streams,,2,DMS is fully secure
"You have setup Direct Connect on one location to ensure your traffic into AWS is going over a private network. You would like to setup a failover connection, that must be as reliable and as redundant as possible, as you cannot afford to be down for too long. What backup connection do you recommend?",multiple-choice,Another Direct Connect setup,Site to Site VPN,Client Side VPN,Snowball Connection,,2,"although this is not as private as another Direct Connect setup, it is definitely more reliable as it leverages the public web. It is the correct answer here"
You would like to transfer data in AWS in less than two days from now. What should you use?,multiple-choice,Setup Direct Connect ,Use the Public Internet,Use AWS Snowball,Use AWS Snowmobile,,2,
